{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For some variables, it would be more useful to know the relationship between them at *daily* scales rather than using monthly averages. \n",
    "<b>Author:</b> Meg Fowler <br>\n",
    "<b>Date:</b> 26 Oct 2020 <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "# Plotting utils \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.ticker as ticker \n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib as matplotlib\n",
    "import cartopy\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.util\n",
    "\n",
    "# Analysis\n",
    "import os\n",
    "import numpy as np \n",
    "import xarray as xr\n",
    "import datetime\n",
    "from   datetime import date, timedelta\n",
    "import pandas as pd \n",
    "#import regionmask\n",
    "import pickle\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for the UV daily data, since this is such a large dataset, only the lowest three levels were selected via the NCO command: <br> \n",
    "<i>ncrcat -d lev,950.0,999.0 -v U,V f.e20.FHIST.f09_f09.cesm2_1.001.cam.h1.199* f.e20.FHIST.f09_f09.cesm2_1.001.cam.h1.1990-99_sfcLevs-dailyUV.nc</i> <br><br>\n",
    "Once those files have been read in here, a new pickle file is created that contains the total surface wind speed, rather than U and V seperately. Once that pickle file is available, the original UV files will be deleted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories \n",
    "dataDir    = '/Users/mdfowler/Documents/Analysis/CLUBB_initial/data/daily/'\n",
    "nameStart  = 'f.e20.FHIST.f09_f09.cesm2_1.001.cam.h1.'\n",
    "nameEnd_UV = '_sfcLevs-dailyUV.nc'\n",
    "nameEnd_FLX  = '_dailySfcFluxes.nc'\n",
    "\n",
    "decadeList = ['1970-79','1980-89','1990-99']\n",
    "#decadeList = ['1990-99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-a62247b44c48>:16: RuntimeWarning: invalid value encountered in less\n",
      "  iceMask[iceContent<10000] = 1\n"
     ]
    }
   ],
   "source": [
    "# Read in single history file to get lat/lon and masks \n",
    "testName = '/Users/mdfowler/Documents/Analysis/CLUBB_initial/data/f.e20.FHIST.f09_f09.cesm2_1.001.clm2.h0.1989-12.nc'\n",
    "testDF   = xr.open_dataset(testName)\n",
    "\n",
    "# Set lat, lon \n",
    "lat = testDF.lat\n",
    "lon = testDF.lon\n",
    "\n",
    "# Make land mask\n",
    "landMask              = testDF.landmask.values\n",
    "landMask[landMask==0] = np.nan\n",
    "\n",
    "# Ideally, want to mask out Greenland/Antarctica too (ice sheets)\n",
    "iceContent = testDF.ICE_CONTENT1.values[0,:,:]  # \"Initial gridcell total ice content\"\n",
    "iceMask    = np.full([len(lat),len(lon)], np.nan)\n",
    "iceMask[iceContent<10000] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e5f272e26ea6>:11: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  flxDF['time'] = flxDF.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with decade  1970-79  ... \n",
      "Done with decade  1980-89  ... \n",
      "Done with decade  1990-99  ... \n"
     ]
    }
   ],
   "source": [
    "# Read in data by decade \n",
    "for iDec in range(len(decadeList)): \n",
    "    \n",
    "    # Open datasets for each decade \n",
    "#     UVfile = dataDir+nameStart+decadeList[iDec]+nameEnd_UV \n",
    "#     windDF = xr.open_dataset(UVfile, decode_times=True)\n",
    "#     windDF['time'] = windDF.indexes['time'].to_datetimeindex()   \n",
    "    \n",
    "    FLXfile = dataDir+nameStart+decadeList[iDec]+nameEnd_FLX\n",
    "    flxDF   = xr.open_dataset(FLXfile, decode_times=True)\n",
    "    flxDF['time'] = flxDF.indexes['time'].to_datetimeindex()\n",
    "    \n",
    "    # Create *giant* datasets that span the full period of the simulations\n",
    "    if iDec==0:\n",
    "#         fullUV   = windDF\n",
    "        fullFLX  = flxDF\n",
    "    else:\n",
    "#         fullUV   = xr.concat([fullUV, windDF], dim=\"time\")\n",
    "        fullFLX  = xr.concat([fullFLX, flxDF], dim=\"time\")\n",
    "        \n",
    "    # Close files \n",
    "#     windDF.close() \n",
    "    flxDF.close()\n",
    "\n",
    "        \n",
    "    print('Done with decade ', decadeList[iDec], ' ... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to easily access years, months, days - use Pandas \n",
    "dates = pd.DatetimeIndex(flxDF['time'].values) \n",
    "\n",
    "# Let's set the monthly averages to be roughly mid-month\n",
    "#   This way, the average for January has a month of 1 instead of being the first day of February \n",
    "midTime = dates - timedelta(days=15)       # Get new dates array that has the right month/year in it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into individual arrays for easy access\n",
    "SHFLX = fullFLX.SHFLX.values\n",
    "LHFLX = fullFLX.LHFLX.values\n",
    "# U     = fullUV.U.values              # Zonal wind (m/s)\n",
    "# V     = fullUV.V.values              # Meridional wind (m/s)\n",
    "\n",
    "# # Flip along vertical (level) axis, so that index 0 is surface \n",
    "# U   = np.flip(U, axis=1)\n",
    "# V   = np.flip(V, axis=1)\n",
    "\n",
    "# # Save levels themselves to arrays and flip them \n",
    "# lev_middle    = np.flip(fullUV.lev.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get surface wind magnitude and combine variances \n",
    "# windSpd = np.sqrt(U**2 + V**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file:  /Users/mdfowler/Documents/Analysis/CLUBB_initial/data/daily/1990-99_totalWindSpeeds.p\n"
     ]
    }
   ],
   "source": [
    "# # Save wind speed out to a pickle file\n",
    "# fileOutName = dataDir+decadeList[0]+'_totalWindSpeeds.p'\n",
    "# pickle.dump( [windSpd,lev_middle], open( fileOutName, \"wb\" ), protocol=4 )\n",
    "# print('Saved file: ', fileOutName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read in pickle files that contain total surface wind speeds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wind speed from pickle file:\n",
    "windSpd = np.full([np.shape(SHFLX)[0], 3, len(lat), len(lon)], np.nan)  # (all times, 3 levels, lat, lon)\n",
    "\n",
    "iStartTime = 0 \n",
    "for iDec in range(len(decadeList)):\n",
    "    # Read in file for one decade\n",
    "    fileOutName              = dataDir+decadeList[iDec]+'_totalWindSpeeds.p'\n",
    "    \n",
    "    with open(fileOutName, \"rb\") as f:\n",
    "        windSpd_temp, lev_middle = pickle.load(f)\n",
    "    \n",
    "    # Save to larger array \n",
    "    nTime      = np.shape(windSpd_temp)[0]\n",
    "    windSpd[iStartTime:nTime+iStartTime,:,:,:] = windSpd_temp\n",
    "    iStartTime = iStartTime+nTime\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carry out linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linRegress3D(xVar, yVar):\n",
    "    \n",
    "    # Get length of lat/lon dimensions \n",
    "    shapeDat = np.shape(xVar)\n",
    "    nlat     = shapeDat[1]\n",
    "    nlon     = shapeDat[2]\n",
    "    \n",
    "    # Define empty arrays to return \n",
    "    slope     = np.full([nlat, nlon], np.nan)\n",
    "    intercept = np.full([nlat, nlon], np.nan)\n",
    "    rValue    = np.full([nlat, nlon], np.nan)\n",
    "    pValue    = np.full([nlat, nlon], np.nan)\n",
    "    \n",
    "    for ilat in range(len(lat)):\n",
    "        for ilon in range(len(lon)): \n",
    "            x = xVar[:,ilat,ilon]\n",
    "            y = yVar[:,ilat,ilon]\n",
    "\n",
    "            # Perform linear regression\n",
    "            slope[ilat,ilon], intercept[ilat,ilon], rValue[ilat,ilon], pValue[ilat,ilon], std_err = stats.linregress(x, y)\n",
    "\n",
    "\n",
    "    return(slope,intercept,rValue,pValue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out surface layer of wind speed\n",
    "#   Levels are: [992.56, 976.33, 957.49] \n",
    "sfcWindSpd      = windSpd[:,0,:,:]\n",
    "\n",
    "# Use only land points... (and exclude ice sheets)\n",
    "sfcWindSpd_land = sfcWindSpd*landMask*iceMask\n",
    "SHFLX_land      = SHFLX*landMask*iceMask\n",
    "LHFLX_land      = LHFLX*landMask*iceMask\n",
    "\n",
    "# Also consider using the bowen ratio or EF rather than fluxes individually (more holistic energy concept)\n",
    "EF_land         = LHFLX_land / (LHFLX_land + SHFLX_land)\n",
    "bowen_land      = SHFLX_land / LHFLX_land\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get seasonal indices \n",
    "iDJF = np.where((midTime.month==12) | (midTime.month<=2))[0]\n",
    "iMAM = np.where((midTime.month>=3)  & (midTime.month<=5))[0]\n",
    "iJJA = np.where((midTime.month>=6)  & (midTime.month<=8))[0]\n",
    "iSON = np.where((midTime.month>=9)  & (midTime.month<=11))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now pick out JJA values: \n",
    "sfcWindSpd_JJA = sfcWindSpd_land[iJJA,:,:]\n",
    "SHFLX_JJA      = SHFLX_land[iJJA,:,:]\n",
    "LHFLX_JJA      = LHFLX_land[iJJA,:,:]\n",
    "EF_JJA         = EF_land[iJJA,:,:]\n",
    "bowen_JJA      = bowen_land[iJJA,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Regression between wind speed and surface fluxes completed...\n",
      "...Regression between wind speed and EF/Bowen ratio completed...\n"
     ]
    }
   ],
   "source": [
    "# Linear regression between mean wind speed and SHFLX \n",
    "slope_SpdSHF_JJA,intercept_SpdSHF_JJA,rValue_SpdSHF_JJA,pValue_SpdSHF_JJA = linRegress3D(sfcWindSpd_JJA, np.abs(SHFLX_JJA))\n",
    "\n",
    "# Linear regression between mean wind speed and LHFLX\n",
    "slope_SpdLHF_JJA,intercept_SpdLHF_JJA,rValue_SpdLHF_JJA,pValue_SpdLHF_JJA = linRegress3D(sfcWindSpd_JJA, np.abs(LHFLX_JJA))\n",
    "print('...Regression between wind speed and surface fluxes completed...')\n",
    "\n",
    "# Linear regression between mean wind speed and evaporative fraction \n",
    "slope_SpdEF_JJA,intercept_SpdEF_JJA,rValue_SpdEF_JJA,pValue_SpdEF_JJA = linRegress3D(sfcWindSpd_JJA, EF_JJA)\n",
    "\n",
    "# Linear regresion between mean wind speed and bowen ratio \n",
    "slope_SpdBowen_JJA,intercept_SpdBowen_JJA,rValue_SpdBowen_JJA,pValue_SpdBowen_JJA = linRegress3D(sfcWindSpd_JJA, bowen_JJA)\n",
    "print('...Regression between wind speed and EF/Bowen ratio completed...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check out where correlation coefficients - higher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of correlation coefficients > 0.50: \n",
      "   SpdSHF_JJA:   0.0546\n",
      "   SpdLHF_JJA:   0.1001\n",
      "   SpdEF_JJA:    0.0576\n",
      "   SpdBowen_JJA: 0.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-ad8d71f926a6>:5: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  spdSHF_JJA_count   = len(np.where(np.abs(rValue_SpdSHF_JJA)>=threshold)[0])/len(np.where(np.isfinite(rValue_SpdSHF_JJA)==True)[0])\n",
      "<ipython-input-25-ad8d71f926a6>:6: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  spdLHF_JJA_count   = len(np.where(np.abs(rValue_SpdLHF_JJA)>=threshold)[0])/len(np.where(np.isfinite(rValue_SpdLHF_JJA)==True)[0])\n",
      "<ipython-input-25-ad8d71f926a6>:7: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  spdEF_JJA_count    = len(np.where(np.abs(rValue_SpdEF_JJA)>=threshold)[0])/len(np.where(np.isfinite(rValue_SpdEF_JJA)==True)[0])\n",
      "<ipython-input-25-ad8d71f926a6>:8: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  spdBowen_JJA_count = len(np.where(np.abs(rValue_SpdBowen_JJA)>=threshold)[0])/len(np.where(np.isfinite(rValue_SpdBowen_JJA)==True)[0])\n"
     ]
    }
   ],
   "source": [
    "# Define threshold for cutting off values of slopes as 'significant'\n",
    "threshold = 0.50 \n",
    "\n",
    "# Get fraction of correlation coefficients above threshold \n",
    "spdSHF_JJA_count   = len(np.where(np.abs(rValue_SpdSHF_JJA)>=threshold)[0])/len(np.where(np.isfinite(rValue_SpdSHF_JJA)==True)[0])\n",
    "spdLHF_JJA_count   = len(np.where(np.abs(rValue_SpdLHF_JJA)>=threshold)[0])/len(np.where(np.isfinite(rValue_SpdLHF_JJA)==True)[0])\n",
    "spdEF_JJA_count    = len(np.where(np.abs(rValue_SpdEF_JJA)>=threshold)[0])/len(np.where(np.isfinite(rValue_SpdEF_JJA)==True)[0])\n",
    "spdBowen_JJA_count = len(np.where(np.abs(rValue_SpdBowen_JJA)>=threshold)[0])/len(np.where(np.isfinite(rValue_SpdBowen_JJA)==True)[0])\n",
    "\n",
    "# Print some summary values \n",
    "print('Fraction of correlation coefficients > %.2f: ' % (threshold))\n",
    "print('   SpdSHF_JJA:   %.4f' % (spdSHF_JJA_count))\n",
    "print('   SpdLHF_JJA:   %.4f' % (spdLHF_JJA_count))\n",
    "print('   SpdEF_JJA:    %.4f' % (spdEF_JJA_count))\n",
    "print('   SpdBowen_JJA: %.4f' % (spdBowen_JJA_count))\n",
    "\n",
    "\n",
    "## Define mask based on where corrCoef >= 0.7 for spdVar and varPBL;\n",
    "#    Mask based on where corrCoef>=0.5 otherwise. \n",
    "# maskR_spdSHF = np.full([len(lat), len(lon)], np.nan)\n",
    "# maskR_spdSHF[np.abs(rValue_SpdSHF_JJA)>=0.5] = 1 \n",
    "\n",
    "# maskR_spdLHF = np.full([len(lat), len(lon)], np.nan)\n",
    "# maskR_spdLHF[np.abs(rValue_SpdLHF_JJA)>=0.5] = 1\n",
    "\n",
    "# maskR_spdEF = np.full([len(lat), len(lon)], np.nan)\n",
    "# maskR_spdEF[np.abs(rValue_SpdEF_JJA)>=0.5] = 1\n",
    "\n",
    "# maskR_spdBowen = np.full([len(lat), len(lon)], np.nan)\n",
    "# maskR_spdBowen[np.abs(rValue_SpdBowen_JJA)>=0.5] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing/Debug section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure compiling method for windSpd pickle files functions as expected (doesn't step on previous time step or anything)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 4., 6., 3., 1., 2., 4., 6., 3.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = np.asarray([1,2,4,6,3])\n",
    "# xFull = np.full([len(x)*2], np.nan)\n",
    "\n",
    "# iStartTime = 0 \n",
    "# for iDec in range(2):\n",
    "#     xFull[iStartTime:len(x)+iStartTime] = x \n",
    "#     iStartTime = iStartTime+len(x)\n",
    "    \n",
    "# xFull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
